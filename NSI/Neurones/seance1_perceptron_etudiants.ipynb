{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9757f28",
   "metadata": {},
   "source": [
    "# TP Réseaux de Neurones – Séance 1\n",
    "## Le perceptron simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42534bca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Objectifs\n",
    "- Comprendre le parallèle entre neurone biologique et neurone artificiel.\n",
    "- Implémenter un perceptron en Python.\n",
    "- L'entraîner sur un petit jeu de données 2D.\n",
    "- Visualiser la frontière de décision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41f6a8-05d5-40f6-8f59-7e9ccbe035a8",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Jusqu'au début du XXème siècle, on pensait que notre cerveau fonctionnait à partir de donnée claires pour fournir un résultat clair. Cette vision déterministe (on parle aussi de vision mécaniste) de l'esprit correspond à celle d'un arbre rigide de décision. Cette vision mécaniste à évolué de nos jours et l'on considère que notre cerveau, sur la base de données incomplètes, voire contradictoires, est capable de trouver des moyens de progresser. C'est cette version probabiliste que les réseaux de neurones essayent de modéliser.  \n",
    "Les réseaux de neurones sont un modèle de calcul qui essaye d'imiter le fonctionnement du cerveau animal où de nombreuses unités simples (neurones biologiques) travaillent en parallèle sans unité de contrôle centralisée.\n",
    "Nous allons voir comment les premiers chercheurs sont passé du neurone biologique au précurseur des réseaux de neurones : le perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0ffe5",
   "metadata": {},
   "source": [
    "## 2. Du neurone biologique au neurone artificiel\n",
    "\n",
    "Un neurone biologique est une cellule nerveuse contenant un soma (corps cellulaire), de nombreuses dendrites (fibres sortant du soma) reliées chacune à un axone d'un neurone voisin, et un seul axone qui peut se ramifier ensuite des centaines de fois pour se connecter à d'autres dendrites. Des synapses sont à la jonction (interface) entre un axone et une dendrite. Un neurone peut envoyer des impulsions électrochimiques qui se déplacent le long de l'axone et activent les connexions synaptiques d'autres neurones.\n",
    "\n",
    "![Neurone biologique](https://raw.githubusercontent.com/thierrycondamines/enseignements/main/NSI/Neurones/Neurone_biologique.jpeg)\n",
    "\n",
    "Si, dans l'histoire ancienne, on pensait que le siège de la conscience se situait dans le coeur ou la rate, on a commencé, au XVIIIème siècle, à l'attribuer au cerveau. On a ensuite pu cartographier dès la fin du XIXème siècle le cerveau animal et les outils d'imagerie modernes permettent aujourd'hui de suivre les signaux lorsqu'ils se déplacent entre les neurones.  \n",
    "C'est la raison pour laquelle l'étude du cerveau animal a poussé les premiers chercheurs en informatique à envisager la possibilité d'une intelligence artificielle, en particulier en essayant de copier le cerveau biologique. C'est ainsi qu'est apparu en 1957, au laboratoire aéronautique de la société Cornell aux Etats-Unis, le premier neurone artificiel appelé Perceptron et inventé par Frank Rosenblatt. Cette découverte a été qualifiée à l'époque par le New York Times d'\"embryon d'un ordinateur électronique que la Navy attend et qui sera capable de marcher, parler, voir, écrire, se reproduire et être conscient de son existence\".\n",
    "Ce modèle de neurone fut implémenté pour la première fois dans l'IBM 704 et, plus tard, dans la Mark I Perceptron qui avait été conçue poru la reconnaissance d'images à des fins militaires pour la Navy.\n",
    "Mais ces travaux doivent beaucoup aux travaux de McCulloch et Pitts qui ont introduit, en 1943, le concept de base de l'activité neuronale à partir de notions de seuils et de sommes pondérées. Cela les a conduit à créer une unité logique de seuil (TLU) qui pouvait apprendre les fonctions logiques ET et OU.\n",
    "### 1.1. Définition du perceptron\n",
    "\n",
    "Le but est de pouvoir classifier un jeu de données, c'est à dire de trouver un hyperplan qui sépare ces données en deux classe. Bien entendu ce n'est pas toujours possible. Lorsque c'est possible on parle d'un jeu de données linéairement séparable.\n",
    "Le perceptron (ou perceptron monocouche) est un classifieur binaire d'un modèle linéaire à n entrées et une sortie. Plus précisément, si on considère $n$ entrées $x_i$ (issues des dendrites) et $n$ poids synaptiques $w_i$ associés à chaque entrée, on fait la somme pondérée des $n$ entrées que l'on envoie à une fonction d'activation avec un seuil défini. Historiquement on utilise une fonction de Heaviside. Cette fonction génère en sortie une valeur binaire unique (0 ou 1) selon l'entrée et caractérisant ainsi une classe : \n",
    "$$\n",
    "\\forall x \\in \\mathbb{R}, H(x) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        0 & \\mbox{si } x < 0 \\\\\n",
    "        1 & \\mbox{si } x \\geq 0 \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "Pour simplifier nos algorithmes nous allons modifier cette fonction en une fonction qui retourne -1 ou 1 (fonction signe) :\n",
    "$$\n",
    "\\forall x \\in \\mathbb{R}, signe(x) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        -1 & \\mbox{si } x < 0 \\\\\n",
    "        1 & \\mbox{si } x \\geq 0 \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "La sortie du perceptron est alors :\n",
    "$$\n",
    "y = signe(\\sum_i w_i.x_i)\n",
    "$$\n",
    "![Perceptron monocouche](https://raw.githubusercontent.com/thierrycondamines/enseignements/main/NSI/Neurones/perceptron.png)\n",
    "\n",
    "### 1.2 Algorithme d'apprentissage\n",
    "Le principe d'apprentissage d'un neurone artificiel est de modifier les poids jusqu'à ce que tous les enregistrements d'entrée soient correctement classifiés. Si l'entrée n'est pas linéairement séparable l'algorithme ne se termine pas. \n",
    "\n",
    "Il existe plusieurs algorithmes d'apprentissage. Considérons un jeu de données labellisées $D = \\{(X_1,y_1), ..., (X_k,y_k)\\}$ où les $X_i$ sont des vecteurs d'entrées et les $y_i$ sont leur classe. Comme on est dans le cas d'un classifieur binaire, on prendra par convention $y_i \\in \\{-1, 1\\}$. On parle de jeux de données labellisées car on sait, pour chaque vecteur du jeu, à quelle classe il appartient. Le but est ensuite, une fois l'apprentissage fait à partir de ce jeu connu, de pouvoir classifier des données inconnues.\n",
    "Prenons un vecteur de poids $W = (w_1, ..., w_n)^T$ choisi aléatoirement (plutôt des petites valeurs), pour chaque vecteur d'entrée du jeu de données d'apprentissage $X_i = (x_{i,1}, ..., x_{i,n})^T$, la sortie du perceptron correspond à $\\hat y_i=signe(W.X_i)$. On peut alors avoir 3 cas de figure :\n",
    "- $\\hat y_i = y_i$ : l'exemple i est bien classé, on ne modifie pas $W$;\n",
    "- $\\hat y_i = 1$ alors que $y_i = -1$ : on diminue les valeurs des poids afin de diminuer le produit saclaire $W.X_i$;\n",
    "- $\\hat y_i = -1$ alors que $y_i = 1$ : on augmente les valeurs des poids afin d'augmenter le produit saclaire $W.X_i$;\n",
    "\n",
    "On utilise la règle de mise à jour des poids suivante :\n",
    "$$ W \\leftarrow W + \\eta.(y_i - \\hat y_i).X_i$$\n",
    "où $\\eta$ est un paramètre appelé taux (ou pas) d'apprentissage (learning rate) qui permet de régler l'amplitude de la mise à jour.\n",
    "On peut remarquer que, dans notre cas, $y_i - \\hat y_i \\in \\{-2,0,2\\}$.\n",
    "D'où l'algorithme d'apprentissage :\n",
    "- nbDonnéesMalClasses = 1\n",
    "- Tant que nbDonnéesMalClasses $\\neq 0$ ET que le nombre d'itération max n'est pas atteint\n",
    "  - nbDonnéesMalClasses = 0\n",
    "  - Pour chaque donnée X_i\n",
    "    - calculer $\\hat y_i$\n",
    "    - Si $\\hat y_i \\neq y_i$ alors\n",
    "      - nbDonnéesMalClasses = nbDonnéesMalClasses + 1\n",
    "      - On met à jour les poids $ W \\leftarrow W + \\eta.(y_i - \\hat y_i).X_i$\n",
    "  - On incrémente le nombre d'itération"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7093e4f-2949-4852-87df-e98d4887520f",
   "metadata": {},
   "source": [
    "## 3. Premier test du perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f1cbd",
   "metadata": {},
   "source": [
    "### 3.1. Génération d’un jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c129c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créons deux nuages de points\n",
    "np.random.seed(0)\n",
    "class0 = np.random.randn(50, 2) + np.array([-2, 2])\n",
    "class1 = np.random.randn(50, 2) + np.array([2, -2])\n",
    "\n",
    "X = np.vstack((class0, class1))\n",
    "y = np.array([-1]*50 + [1]*50)\n",
    "\n",
    "# Affichage\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='bwr')\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Jeu de données\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6bc52a",
   "metadata": {},
   "source": [
    "### 3.2. Initialisation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d567af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisons les poids w avec des valeurs aléatoires\n",
    "w = np.random.randn(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e734e4",
   "metadata": {},
   "source": [
    "### 3.3. Fonction d’activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37413de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signe(x):\n",
    "    return -1 if x<0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4b944",
   "metadata": {},
   "source": [
    "### 3.4. Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    return signe(np.dot(X, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06cfb14-4cab-4bf1-b92f-ca07f54c9aea",
   "metadata": {},
   "source": [
    "### 3.5. Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be2958-456a-4196-be2f-7c4f21342952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "\n",
    "lr = 0.1        # Learning rate\n",
    "iteMax = 1000   # Nombre maximum d'itération\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec7333-136b-414e-852f-b947d2993d24",
   "metadata": {},
   "source": [
    "### 3.6. Visualisation de la frontière de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5abf7-9efe-44c0-9f0a-0ebb7025d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = X[:,0].min()-1, X[:,0].max()+1\n",
    "x2_min, x2_max = X[:,1].min()-1, X[:,1].max()+1\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min,x1_max,100),\n",
    "                       np.linspace(x2_min,x2_max,100))\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "preds=[]\n",
    "for i in range(len(grid)):\n",
    "    preds.append(predict(grid[i], w))\n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(xx1.shape)\n",
    "\n",
    "plt.contourf(xx1, xx2, preds, levels=[-1,0,1], cmap=\"bwr\", alpha=0.2)\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=\"bwr\", edgecolors=\"k\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.title(\"Frontière de décision du perceptron\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba21fd-d10d-4217-b5df-8a10b3a1064a",
   "metadata": {},
   "source": [
    "### 3.7. Remarques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b0820-613a-4e9e-8650-4d9de547127d",
   "metadata": {},
   "source": [
    "- Les droites de séparations susceptibles d’être trouvées par l’algorithme du perceptron sont de la forme : $w_1.x+w_2.y=0$. Elles passent donc toutes par l'origine.\n",
    "- Si les données ne sont pas séparables par une droite passant par l’origine, l’algorithme ne pourra pas déterminer une droite de séparation des données. Elles pourraient toutefois être séparées par une droite ne passant pas par l'origine.\n",
    "\n",
    "Pour remédier à ce problème, on ajoute au produit scalaire $W.X$ un paramètre b indépendant des entrées. Ce paramètre est appelé biais. Pour faciliter les calculs, on place ce biais dans le vecteur de poids, par exemple comme le poids $w_0$, et on rajoute une composante $X_0=1$ dans le vecteur $X$.\n",
    "L'algorithme d'apprentissage va alors devoir trouver, en plus des bons poids, le bon biais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c663471-d0cc-4db4-8a5a-531cfc3d15e5",
   "metadata": {},
   "source": [
    "## 4. Perceptron avec biais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c6b9d-6459-42ba-8264-db044166d0c1",
   "metadata": {},
   "source": [
    "### 4.1. Génération d'un jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c1593-7580-4baf-801f-59d8334ca8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créons deux nuages de points\n",
    "np.random.seed(0)\n",
    "class0 = np.random.randn(50, 2)\n",
    "class1 = np.random.randn(50, 2) + np.array([4, 4])\n",
    "\n",
    "X = np.vstack((class0, class1))\n",
    "y = np.array([-1]*50 + [1]*50)\n",
    "\n",
    "# On insere un 1 en 1ere composante (composante 0) pour tous les X_i\n",
    "un = np.array([1]*100)\n",
    "X = np.insert(X,0,un,axis=1)\n",
    "\n",
    "# Affichage\n",
    "plt.scatter(X[:,1], X[:,2], c=y, cmap='bwr')\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Jeu de données\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91461185-2c91-46e9-b61c-1dbb312bb524",
   "metadata": {},
   "source": [
    "### 4.2. Initialisation des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2295f-f720-4f0f-a3b3-c20e58dc5480",
   "metadata": {},
   "source": [
    "On rajoute une composante biais en 1ere position $w_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d790f-2409-4211-84f1-b2e7a9fe8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisons les poids w avec des valeurs aléatoires\n",
    "w = np.random.randn(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efe9fc-d559-4791-b252-3afb8588160e",
   "metadata": {},
   "source": [
    "### 4.2. Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9c73a-baa6-4d3d-9ff6-765463b251d8",
   "metadata": {},
   "source": [
    "L'algorithme est le même ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e1def-e9e8-4eb7-8dd5-d8e10b924cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1        # Learning rate\n",
    "iteMax = 1000   # Nombre maximum d'itération\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed8b14-18f5-4091-8dcd-66850f5a149f",
   "metadata": {},
   "source": [
    "### 4.3. Visualisation de la frontière de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1cbe7-68b1-4f93-a0cf-5d5e2bd853ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = X[:,1].min()-1, X[:,1].max()+1\n",
    "x2_min, x2_max = X[:,2].min()-1, X[:,2].max()+1\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min,x1_max,100),\n",
    "                       np.linspace(x2_min,x2_max,100))\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "un = np.array([1]*len(grid))\n",
    "grid = np.insert(grid,0,un,axis=1)\n",
    "preds=[]\n",
    "for i in range(len(grid)):\n",
    "    preds.append(predict(grid[i], w))\n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(xx1.shape)\n",
    "\n",
    "plt.contourf(xx1, xx2, preds, levels=[-1,0,1], cmap=\"bwr\", alpha=0.2)\n",
    "plt.scatter(X[:,1], X[:,2], c=y, cmap=\"bwr\", edgecolors=\"k\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.title(\"Frontière de décision du perceptron\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf958717-e0a2-4c97-9523-d8b3ab1fe199",
   "metadata": {},
   "source": [
    "On peut remarquer ici que la frontière de décision ne passe pas par l'origine. Sa détermination est rendue possible grâce au biais introduit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d582066-9530-4172-a563-9aea70441519",
   "metadata": {},
   "source": [
    "### 4.4. Remarques\n",
    "- On peut prouver (Théorème de Novikoff) que cette méthode converge en un nombre fini d'itérations pour un learning rate $\\eta$ assez petit et des données linéairement séparables.\n",
    "- Si les données ne sont pas linéairement séparables la convergence n'est pas assurée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce0fd2-6c92-4788-a2a0-65013ab34470",
   "metadata": {},
   "source": [
    "## 5. Perceptron avec règle Delta et fonction de coût"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd5ccf-0003-466f-9a7d-a4b24bbd86a3",
   "metadata": {},
   "source": [
    "Nous avons vu qu'on pouvait trouver une solution au problème de classification lorsque les données sont séparables mais que l'algorithme pouvait ne pas converger lorsque les données ne sont pas linéairement séparables. Dans ce cas, une modification de l'algorithme, appelée règle Delta, permet de converger vers la meilleure solution possible. Cette méthode repose sur une minimisation d'une fonction d'erreur.\n",
    "\n",
    "Qui dit recherche d'un minimum, dit calcul de dérivée et donc fonctions dérivables. C'est la raison pour laquelle nous n'allons plus prendre comme fonction d'activation la fonction signe qui n'est pas dérivable mais une autre fonction fréquemment utilisée comme seuil : la fonction sigmoïde : $$s(x) = \\frac{1}{1+e^{-x}}$$\n",
    "Une autre fonction d'activation souvent utilisée est la fonction $tanh$ qui a l'avantage d'être à valeur dans [-1,1] et donc de prendre en compte les négatifs contrairement à la sigmoïde qui est à valeurs dans [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07a3d7-db5d-4ddb-81e9-c35b181bcc9b",
   "metadata": {},
   "source": [
    "### 5.1. Jeu de données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b94bb5-15b7-4287-b102-e490774d68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créons deux nuages de points\n",
    "np.random.seed(0)\n",
    "# Demi-lunes\n",
    "n=200\n",
    "noise=0.2\n",
    "n2 = n // 2\n",
    "t = np.random.rand(n2) * np.pi\n",
    "X1 = np.c_[np.cos(t), np.sin(t)] + noise * np.random.randn(n2, 2)\n",
    "X2 = np.c_[1 - np.cos(t), -np.sin(t) - 0.5] + noise * np.random.randn(n2, 2)\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.array([0]*n2 + [1]*n2)\n",
    "\n",
    "# On insere un 1 en 1ere composante (composante 0) pour tous les X_i\n",
    "X = np.c_[np.ones(len(X)), X]\n",
    "\n",
    "# Affichage\n",
    "plt.scatter(X[:,1], X[:,2], c=y, cmap='bwr')\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Jeu de données\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5280475-a77c-4344-82c5-0dbb6dc0c8ab",
   "metadata": {},
   "source": [
    "### 5.2. Initialisation des poids/biais\n",
    "Pour ne pas \"saturer\" la sigmoïde, on veillera ici à prendre des poids assez petits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a193641-488f-40c1-9c92-b9ae7eb209d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisons les poids w avec des valeurs aléatoires\n",
    "w = 0.01*np.random.randn(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5b7df-8375-49ae-a6e6-0890228c4c3f",
   "metadata": {},
   "source": [
    "### 5.3. Fonction d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1fc45-14df-4c49-b2c9-53786f0cf4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbae46-7cf9-4cb4-88f1-68f27636b363",
   "metadata": {},
   "source": [
    "### 5.5. Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc7fd5-e6b5-42ab-89f5-6d1945f6d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    return sigmoid(np.dot(X, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e66b30",
   "metadata": {},
   "source": [
    "### 5.6. Fonction de coût/perte : l’entropie croisée (binary cross-entropy ou BCE)\n",
    "Le but ici est de mesurer l'erreur en sortie entre la valeur exacte (connue pour un jeu de données d'entrainement) et la valeur obtenue par prédiction. On pourrait bien entendu utiliser une erreur quadratique (Mean Squared Error ou MSE). Si elle est plus simple à formuler, elle n'est pas adaptée à la classification binaire du perceptron avec sigmoïde. On va, au contraire, utiliser l'entropie croisée (Binary Cross-Entropy ou BCE) :\n",
    "$$E(W,D) = -\\frac{1}{N}\\sum(y_i.log(\\hat y_i)+(1-y_i).log(1-\\hat y_i))$$\n",
    "Il y a plusieurs raisons à cela :\n",
    "- La BCE colle statistiquement à notre problème de classification binaire avec des étiquettes 0/1 (Maximum de vraissemblance de Bernoulli) alors que la MSE est mal adaptée à la classification;\n",
    "- le gradient est de meilleur qualité même lorsque la sigmoïde est proche de 0 ou 1, tandis qu'avec MSE, un gradient quasi nul ralenti fortement l'apprentissage (descente de gradient);\n",
    "- avec BCE, la perte/erreur est convexe en W ce qui donne un unique optimum global, tandis qu'avec MSE et sigmoïde la perte n'est pas convexe ce qui complique l'optimisation;\n",
    "- BCE pénalise plus fortement les erreurs importantes (pour $y=1$ et $\\hat y = 0,01$ la perte est de l'ordre de 4,6 avec BCE mais que 0,5 environ avec MSE), d'où des corrections plus franches.\n",
    "\n",
    "Pour un perceptron à sigmoïde, l'entropie croisée permet un apprentissage plus rapide, plus stable et statistiquement correct pour des cibles binaires.\n",
    "Pour éviter les $log(0)$ on rajoute en général un $\\epsilon$ très petit:\n",
    "$$E(W,D) = -\\frac{1}{N}\\sum(y_i.log(\\hat y_i + \\epsilon)+(1-y_i).log(1-\\hat y_i +\\epsilon))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb08498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perte(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    return -np.mean(y_true*np.log(y_pred+eps) + (1-y_true)*np.log(1-y_pred+eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20586f50",
   "metadata": {},
   "source": [
    "### 5.4. Apprentissage (descente de gradient)\n",
    "Nous allons chercher les poids et biais qui minimisent la fonction coût ci-dessus. Appelons $w_1$ et $w_2$ les deux poids de notre perceptron à 2 entrées, et $b$ son biais. Notons toujours $\\hat y$ sa sortie pour une entrée donnée x, et $y$ la sortie réelle attendue. Soit $v = w_1.x_1+w_2.x_2+b$, on a $\\hat y = s(v)$. Pour calculer les poids et biais qui minimisent E, nous allons dériver E par rapports à ces mêmes poids et biais. Pour simplifier les écritures, nous allons considérer l'erreur pour une seule entrée : $E(W)=y.log(\\hat y)+(1-y).log(1-\\hat y)$. On a alors :\n",
    "$$\\frac{\\partial E}{\\partial w_i} = \\frac{\\partial E}{\\partial v}.\\frac{\\partial v}{\\partial w_i}$$\n",
    "Or : $$\\frac{\\partial E}{\\partial v}=\\frac{\\partial E}{\\partial \\hat y}.\\frac{\\partial \\hat y}{\\partial v}$$\n",
    "avec :\n",
    "$$\\frac{\\partial E}{\\partial \\hat y}=-\\frac{y}{\\hat y}+\\frac{1-y}{1- \\hat y}=\\frac{\\hat y - y}{\\hat y . (1- \\hat y)}$$\n",
    "et :\n",
    "$$\\frac{\\partial \\hat y}{\\partial v} = \\frac{s(v)}{\\partial v} = \\hat y . (1- \\hat y)$$\n",
    "d'où : $$\\frac{\\partial E}{\\partial v}= \\hat y - y = \\delta$$\n",
    "Voici le fameux Delta de la règle qui porte son nom. Etant donné que $\\frac{\\partial v}{\\partial w_i} = x_i$, on en déduit :\n",
    "$$\\frac{\\partial E}{\\partial w_i} = \\frac{\\partial E}{\\partial v}.\\frac{\\partial v}{\\partial w_i} = - \\delta . x_i$$\n",
    "et \n",
    "$$\\frac{\\partial E}{\\partial b} = \\frac{\\partial E}{\\partial v}.\\frac{\\partial v}{\\partial b} = - \\delta$$\n",
    "La méthode de descente de gradient nous indique que pour aller vers le minimum, il faut prendre la direction opposée au gradient avec un pas pas trop grand (paramétré par le learning rate) :\n",
    "$$\\Delta w_i = - \\eta. \\frac{\\partial E}{\\partial w_i} = - \\eta.\\delta.x_i$$\n",
    "et $$\\Delta b = - \\eta. \\frac{\\partial E}{\\partial b} = - \\eta.\\delta$$\n",
    "Pour un jeu de N données, nous avions pris une erreur globale moyenne des erreurs sur chaque donnée du jeu : $$E(W,D) = -\\frac{1}{N}\\sum(y_i.log(\\hat y_i + \\epsilon)+(1-y_i).log(1-\\hat y_i +\\epsilon))$$\n",
    "Il faudra donc faire une moyenne des $\\delta^{(k)}$ correspondant à chaque entrée $x^{(k)}$ de notre jeu de données. Et si on intègre le biais comme première composante du vecteur poids W, et nos entrées X avec 1 en première composante, on a alors :\n",
    "$$w_i \\leftarrow w_i + \\Delta w_i = w_i - \\eta . \\frac{1}{N} \\sum_{k=1}^{N}. \\delta^{(k)} . x^{k}_i $$ où $\\delta^{(k)} = \\hat y^{(k)} - y^{(k)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3731ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.1\n",
    "iteMax = 1000\n",
    "pertes = []\n",
    "\n",
    "for ite in range(iteMax):\n",
    "    # prédiction\n",
    "    ...\n",
    "    \n",
    "    # perte\n",
    "    ...\n",
    "    \n",
    "    # gradients\n",
    "    ...\n",
    "    \n",
    "    # mise à jour\n",
    "    ...\n",
    "\n",
    "plt.plot(pertes)\n",
    "plt.xlabel(\"Itérations\")\n",
    "plt.ylabel(\"Perte\")\n",
    "plt.title(\"Évolution de la fonction de coût\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461b737",
   "metadata": {},
   "source": [
    "### 5.5. Visualisation de la frontière de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a742a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = X[:,1].min()-1, X[:,1].max()+1\n",
    "x2_min, x2_max = X[:,2].min()-1, X[:,2].max()+1\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min,x1_max,100),\n",
    "                       np.linspace(x2_min,x2_max,100))\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "un = np.array([1]*len(grid))\n",
    "grid = np.insert(grid,0,un,axis=1)\n",
    "preds=[]\n",
    "for i in range(len(grid)):\n",
    "    preds.append(predict(grid[i], w))\n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(xx1.shape)\n",
    "\n",
    "plt.contourf(xx1, xx2, preds, levels=[0,0.5,1], cmap=\"bwr\", alpha=0.2)\n",
    "plt.scatter(X[:,1], X[:,2], c=y, cmap=\"bwr\", edgecolors=\"k\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.title(\"Frontière de décision du perceptron\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831893c",
   "metadata": {},
   "source": [
    "## 6. Exercices supplémentaires\n",
    "1. Changer le taux d’apprentissage et observer l’effet.   \n",
    "2. Modifier la position des classes pour tester la robustesse du perceptron.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.06-py3.11",
   "language": "python",
   "name": "conda-env-anaconda-2025.06-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
