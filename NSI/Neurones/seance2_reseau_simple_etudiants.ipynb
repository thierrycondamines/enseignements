{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df1c569",
   "metadata": {},
   "source": [
    "# TP Réseaux de Neurones – Séance 2\n",
    "## Réseau à une couche cachée (MLP simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c1f5b8",
   "metadata": {},
   "source": [
    "### Objectifs\n",
    "- Comprendre pourquoi un perceptron simple ne peut pas résoudre le problème du XOR.\n",
    "- Implémenter un réseau à une couche cachée.\n",
    "- Propagation avant et rétropropagation.\n",
    "- Visualiser la frontière de décision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eeeea8",
   "metadata": {},
   "source": [
    "## 1. Le problème du XOR\n",
    "Le jeu de données du \"ou exclusif\" est simple. La sortie $y=1$ si un et un seul des $x_i$ vaut 1 et $y=0$ dans les autres cas. Un problème simple mais qui n'est pas linéairement séparable lorsqu'on voit la disposition des 4 points :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,0])\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=\"bwr\", s=100)\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.title(\"Problème du XOR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733c143-3c14-4c97-86b4-88f9ed509b5a",
   "metadata": {},
   "source": [
    "Le perceptron de base ne peut donc pas résoudre le problème de modélisation posé par la fonction XOR. Cela a constitué un échec cinglant dans les années 60 pour les chercheurs travaillant dans le champ des réseaux de neurones (voir livre \"Perceptron\" de Minsky & Papert (1969) qui détaille les limites du perceptron). Mais ce que l'on n'avait pas compris encore à l'époque (surtout dans l'industrie) c'est qu'en associant plusieurs neurones (comme c'est le cas dans le cerveau animal) on pouvait résoudre le problème du XOR, ce qu'on appellera plus tard le perceptron multicouche. Cet échec public du premier perceptron a découragé les financements pendant une décénie (que l'on nommera période de glaciation pour l'IA, 1974-1980). Quelques travaux ont tout de même continué et ce n'est qu'au milieu des années 80 que les réseaux de neurones ont connu une seconde vague d'intérêt. \n",
    "\n",
    "## 2. Le perceptron multicouche ou réseau feed-forward multicouche\n",
    "Le principe est simple. Il s'agit de disposer des neurones en couches composées de 1 ou plusieurs neurones chacune :\n",
    "- une couche d'entrée qui reçoit les données d'entrée. Le nombre de neurones y est égal au nombre de composantes du vecteur d'entrée. Dans notre réseau feed-forward chaque neurone de la couche d'entrée est relié à tous les neurones de la 1ère couche caché qui suit. Mais il existe d'autres architectures avec des connexions manquantes.\n",
    "- une ou plusieurs couches dites cachées dont les neurones reçoivent en entrée les sorties des neurones de la couche précédente et sont reliés aux neurones de la couche suivante. Ce sont ces couches cachées qui vont permettre de traiter des problèmes non linéaires.\n",
    "- une couche de sortie dont les neurones reçoivent les sorties de la dernière couche cachée et qui fournissent en sortie la réponse/prédiction de notre modèle.\n",
    "![réseau feed forward](https://raw.githubusercontent.com/thierrycondamines/enseignements/main/NSI/Neurones/reseau_neurones.png)\n",
    "Lorsque les données sont entrées dans la couche d'entrée, elles sont envoyées aux neurones de la première couche cachée. Ces neurones vont pondérer (chacun avec des poids et biais spécifiques) ces entrées et produire combinaison linéaire, comme on l'a vu avec le perceptron simple, qui sera passée à la fonction d'activation (souvent à valeurs dans [0,1] ou [-1,1]). Lorsque la valeur sortant d'un neurone est non nulle, on dit qu'elle active le neurone suivant qui la reçoit. Cette propagation vers l'avant dans le réseau a donne son nom de réseau feed-forward.\n",
    "\n",
    "Les neurones d'une même couche peuvent avoir la même fonction d'activation (ce sera notre cas ici) mais ce n'est pas obligatoire. La couche de sortie utilise généralement une fonction d'activation de type sygmoïde ou $softmax$.\n",
    "\n",
    "Pour résoudre le problème du XOR, un réseau 2-2-1 suffit (2 neurones d'entrée, 2 neurones cachés, 1 neurone de sortie). La couche d'entrée ne traîte pas les entrées (pas de poids ni fonction d'activation) et ne fait que les distribuer sur la couche cachée. Pour les fonctions d'activation, nous allons utiliser : \n",
    "- tanh pour les 2 neurones de la couche cachée\n",
    "- sigmoïde pour le neurone de sortie\n",
    "\n",
    "Tanh est ici plus adaptée pour plusieurs raisons :\n",
    "- elle est centrée sur 0 (intervalle [-1,1]) alors que sigmoïde est décalée positive ([0,1]) ce qui évite à la mise à jour des poids de zigzaguer et donc une convergence plus rapide et plus stable;\n",
    "- la pente est plus forte avec tanh autour de 0, ce qui rend l'apprentissage plus \"vif\" (gradient plus grand);\n",
    "- tanh permet de coder la présence ou l'absence d'une caractéristique par des valeurs négatives (absence) ou positives (présence) ce qui est souvent utile;\n",
    "- Même si on peut aproximer XOR avec sigmoïde, l'optimisation est en général plus lente et instable.\n",
    "\n",
    "La fonction sigmoïde, bien qu'historique, est beacoup moins utilisée de nos jours. On la conserve juste dans le neurone de sortie car on veut des sorties 0 ou 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd291356",
   "metadata": {},
   "source": [
    "## 3. Initialisation des paramètres\n",
    "Chaque neurone du réseau a ses poids qui amplifient ou atténuent un signal. Plus un poids est élevé plus l'entrée associée affectera le résultat de sortie. C'est en faisant évoluer ces poids dans la phase d'apprentissage que le réseau va apprendre à l'aveugle les corrélations qui existent entre les données d'entrées et leur caractéristiques (classes) données en sortie.\n",
    "Nous conservons les biais, introduits pour le perceptron simple. Ceux-ci, dans un réseau multicouche, vont garantir l'activation d'au moins quelques neurones par couches même dans le cas d'un signal faible (proche de zéro). Conceptuellement, Ils permettent ainsi au réseau de tester de nouvelles interprétations.\n",
    "\n",
    "Les poids et biais seront à nouveau initialisés aléatoirement mais avec une petite variante : l'initialisation dite de Xavier/Glorot. Cette initialisation, proposée par Xavier Glorot et Joshua Bengio en 2010, propose de prendre les poids dans une loi uniforme $U[-\\sqrt {\\frac{6}{nbin+nbout}},\\sqrt {\\frac{6}{nbin+nbout}}]$, ce qui a pour effet de stabiliser les activations et les gradients dès le départ. Ici, pour la couche cachée $nbin=2$ et $nbout=2$ et pour la couche de sortie $nbin=2$ et $nbout=1$\n",
    "\n",
    "Afin de mieux voir les biais, j'ai choisi de ne pas les intégrer aux vecteurs de poids mais cela reste bien entendu tout à fait possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# Poids des deux neurones de la couche cachée\n",
    "a = np.sqrt(6/4)\n",
    "w1 = np.random.uniform(-a, a)\n",
    "w2 = np.random.uniform(-a, a)\n",
    "w3 = np.random.uniform(-a, a)\n",
    "w4 = np.random.uniform(-a, a)\n",
    "\n",
    "# Biais des 2 neurones de la couche cachée\n",
    "b1 = 0.\n",
    "b2 = 0.\n",
    "\n",
    "# poids du neurone de sortie\n",
    "a=np.sqrt(6/3)\n",
    "w5 = np.random.uniform(-a, a)\n",
    "w6 = np.random.uniform(-a, a)\n",
    "\n",
    "# Biais du neurone de sortie\n",
    "b = 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24b330",
   "metadata": {},
   "source": [
    "## 4. Fonction sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab77bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6426b66",
   "metadata": {},
   "source": [
    "## 5. Fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add88452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perte(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    return -np.mean(y_true*np.log(y_pred+eps) + (1-y_true)*np.log(1-y_pred+eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28a19b",
   "metadata": {},
   "source": [
    "## 6. Rétropropagation\n",
    "L'apprentissage par rétropropagation a été inventé en 1969 par Bryson et Ho mais est resté dans les placards jusque dans le milieu des années 80 où on s'est apperçu de son importance dans la réduction de l'erreur.\n",
    "\n",
    "Nous avons vu, pour un perceptron simple, que, lorsque la sortie correspond à l'étiquette (valeur exacte), on ne change rien et, lorsqu'elle diffère, on ajuste les poids et le biais. La rétropropagation est une généralisation de ce principe à un réseau de plusieurs neurones. Mais comme il y a une multitude de poids dans un réseau de neurones, il s'agit de répartir/diviser la responsabilité de l'erreur entre les poids.\n",
    "\n",
    "Pour un perceptron simple, il n'y a qu'un seul poids par entrée qui influence la sortie. Par contre dans un réseau de neurone, une entrée est reliée à la sortie via une multitude de poids ce qui rend le problème de modification des poids plus complexe. Comme le seul élément qui nous guide est l'erreur en sortie du réseau, on va donc partir de la couche sortie et faire en remontant vers la couche d'entrée (d'où le nom de rétropropagation).\n",
    "\n",
    "Pour bien visualiser le mécanisme de rétropropagation, voici un schéma du réseau où apparaissent séparément chaques paramètres :\n",
    "\n",
    "![perceptron_2_2_1](https://raw.githubusercontent.com/thierrycondamines/enseignements/main/NSI/Neurones/perceptron_2_2_1.png)\n",
    "\n",
    "Pour rappel, en prenant une fonction coût de la forme $E(W)=-[y.log(\\hat y)+(1-y).log(1-\\hat y)]$, nous avions défini un paramètre $\\delta$ :$$\\delta = \\frac{\\partial E}{\\partial v} = \\hat y - y$$\n",
    "\n",
    "### 6.1. Couche de sortie\n",
    "\n",
    "La couche de sortie est composée d'un seul perceptron de poids $w_5$ et $w_6$, donnant une combilaison linéaire de ses entrées $y_1$ et $y_2$ venant des neurones de la couche cachée : $$v = w_5.y_1+w_6.y_2+b$$. Cette combinaison est ensuite passée à la fonction sigmoïde pour donner la sortie finale $\\hat y = s(v)$. On en déduite les dérivées partielles :\n",
    "$$\\frac{\\partial E}{\\partial w_5} = \\frac{\\partial E}{\\partial v}.\\frac{\\partial v}{\\partial w_5} = \\delta.y_1 \\implies \\Delta w_5 = -\\eta \\frac{\\partial E}{\\partial w_5} = -\\eta.\\delta.y_1$$\n",
    "et de la même façon :$$\\frac{\\partial E}{\\partial w_6} =\\delta.y_2 \\implies \\Delta w_6 =  -\\eta.\\delta.y_2$$\n",
    "$$\\frac{\\partial E}{\\partial b} =\\delta \\implies \\Delta b =  -\\eta.\\delta$$\n",
    "\n",
    "### 6.2. Couche cachée\n",
    "\n",
    "Il s'agit ici de voir l'impact des poids $w_1, ..., w_4$, sur l'erreur de sortie. Les deux neurones de cette couche cachée on une fonction d'activation de type $\\phi(x)=tanh(x)$ ce qui nous donne $y_i = \\phi (v_i) = tanh(v_i)$ et par suite $$\\frac{\\partial y_i}{\\partial v_i} = 1 - tanh^2 (v_i) = 1 - y_i^2$$\n",
    "Passons maintenant aux dérivées partielles par rapport aux poids de cette couche :\n",
    "$$\\frac{\\partial E}{\\partial w_1} = \\frac{\\partial E}{\\partial v}.\\frac{\\partial v}{\\partial y_1}.\\frac{\\partial y_1}{\\partial v_1}.\\frac{\\partial v_1}{\\partial w_1} = \\delta.w_5.(1-y_1^2).x_1$$\n",
    "Remarquons ici que le calcul de cette dérivée se fait en partant de la sortie et en remontant le long des branches du réseau jusqu'à $w_1$. Comme on l'avait fait pour le paramètre $\\delta$, on peut poser $\\delta_1 = \\delta.w_5.(1-y_1^2)$ ce qui nous donne :\n",
    "$$\\frac{\\partial E}{\\partial w_1} = \\delta_1 . x_1 \\implies \\Delta w_1 =  -\\eta.\\delta_1.x_1$$\n",
    "et de la même manière on obtient :\n",
    "$$\\frac{\\partial E}{\\partial w_3} =\\delta.w_5.(1-y_1^2).x_2 \\implies \\Delta w_3 =  -\\eta.\\delta_1.x_2$$\n",
    "$$\\frac{\\partial E}{\\partial b_1} =\\delta_1 \\implies \\Delta b_1 =  -\\eta.\\delta_1$$\n",
    "et, en posant $\\delta_2 = \\delta.w_6.(1-y_2^2)$ :\n",
    "$$\\frac{\\partial E}{\\partial w_2} =\\delta_2.x_1 \\implies \\Delta w_2 =  -\\eta.\\delta_2.x_1$$\n",
    "$$\\frac{\\partial E}{\\partial w_4} =\\delta_2.x_2 \\implies \\Delta w_4 =  -\\eta.\\delta_2.x_2$$\n",
    "$$\\frac{\\partial E}{\\partial b_2} =\\delta_2 \\implies \\Delta b_2 =  -\\eta.\\delta_2$$\n",
    "\n",
    "### 6.3. Traitement de l'ensemble du jeu de données (batch)\n",
    "Les calculs ci-dessus ont été fait pour une donnée d'entrée (pour simplifier les écritures). Dans le cas réel d'un jeu de N données notre fonction coût globale est moyenne des coûts pour chaque donnée :\n",
    "$$E(W,D) = -\\frac{1}{N}\\sum_{k=1}^{N}(y_k.log(\\hat y_k + \\epsilon)+(1-y_k).log(1-\\hat y_k +\\epsilon))$$\n",
    "Ce qui nous donne les formules suivantes :\n",
    "- couche de sortie (en notant $\\delta^{(k)} = \\hat y^{(k)} - y^{(k)}$) :\n",
    "$$\\Delta w_5 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta^{(k)}.y_1^{(k)}$$\n",
    "$$\\Delta w_6 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta^{(k)}.y_2^{(k)}$$\n",
    "$$\\Delta b = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta^{(k)}$$\n",
    "- couche cachée (en notant $\\delta_1^{(k)} = \\delta^{(k)}.w_5. (1 - {y_1^{(k)}}^2)$ et $\\delta_2^{(k)} = \\delta^{(k)}.w_6. (1 - {y_2^{(k)}}^2)$ ) :\n",
    "$$\\Delta w_1 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta_1^{(k)}.x_1^{(k)}$$\n",
    "$$\\Delta w_3 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta_1^{(k)}.x_2^{(k)}$$\n",
    "$$\\Delta w_2 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta_2^{(k)}.x_1^{(k)}$$\n",
    "$$\\Delta w_4 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta_2^{(k)}.x_2^{(k)}$$\n",
    "$$\\Delta b_1 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta_1^{(k)}$$\n",
    "$$\\Delta b_2 = -\\eta.\\frac{1}{N} \\sum_{k=1}^{N}. \\delta_2^{(k)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7c226",
   "metadata": {},
   "source": [
    "## 6. Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : boucle d’apprentissage\n",
    "lr=0.1\n",
    "iteMax=30000\n",
    "pertes=[]\n",
    "\n",
    "for ite in range(iteMax):\n",
    "    \n",
    "    # ----- Forward -----\n",
    "    # Couche cachée\n",
    "    ...\n",
    "\n",
    "    # Couche sortie\n",
    "    ...  \n",
    "\n",
    "    # ----- Perte  -----\n",
    "    ...\n",
    "\n",
    "    # ----- Backward -----\n",
    "    ...\n",
    "   \n",
    "plt.plot(pertes)\n",
    "plt.title(\"Évolution de la perte\")\n",
    "plt.xlabel(\"Itérations\"); plt.ylabel(\"perte\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3ad6f-f07d-4615-89f6-4f3412dfdd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontière de décision\n",
    "xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 200),\n",
    "                     np.linspace(-0.5, 1.5, 200))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "v1g = w1*grid[:,0] + w3*grid[:,1] + b1\n",
    "v2g = w2*grid[:,0] + w4*grid[:,1] + b2\n",
    "y1g = np.tanh(v1g)\n",
    "y2g = np.tanh(v2g)\n",
    "vg  = w5*y1g + w6*y2g + b\n",
    "zz  = sigmoid(vg).reshape(xx.shape)\n",
    "\n",
    "cf = plt.contourf(xx, yy, zz, levels=50, alpha=0.6)\n",
    "plt.colorbar(cf, label=\"p(y=1)\")\n",
    "cs = plt.contour(xx, yy, zz, levels=[0.5], linewidths=2)\n",
    "plt.clabel(cs, fmt={0.5: 'p=0.5'})\n",
    "plt.scatter(X[y==0,0], X[y==0,1], label=\"Classe 0\", edgecolors='k')\n",
    "plt.scatter(X[y==1,0], X[y==1,1], label=\"Classe 1\", edgecolors='k')\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\"); plt.title(\"Frontière de décision MLP 2–2–1\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.06-py3.11",
   "language": "python",
   "name": "conda-env-anaconda-2025.06-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
